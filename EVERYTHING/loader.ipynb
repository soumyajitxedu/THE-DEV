{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec6fcf7",
   "metadata": {},
   "source": [
    "### loader and datasets and batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100c5a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 159.68613386154175\n",
      "Epoch 2/100, Loss: 153.5729637145996\n",
      "Epoch 3/100, Loss: 146.80066585540771\n",
      "Epoch 4/100, Loss: 141.69225692749023\n",
      "Epoch 5/100, Loss: 134.99475288391113\n",
      "Epoch 6/100, Loss: 128.98412322998047\n",
      "Epoch 7/100, Loss: 123.03753709793091\n",
      "Epoch 8/100, Loss: 116.20396423339844\n",
      "Epoch 9/100, Loss: 109.35155487060547\n",
      "Epoch 10/100, Loss: 104.1479721069336\n",
      "Epoch 11/100, Loss: 97.96838855743408\n",
      "Epoch 12/100, Loss: 91.56362462043762\n",
      "Epoch 13/100, Loss: 84.52335834503174\n",
      "Epoch 14/100, Loss: 77.79816484451294\n",
      "Epoch 15/100, Loss: 72.96484327316284\n",
      "Epoch 16/100, Loss: 67.6414589881897\n",
      "Epoch 17/100, Loss: 61.44706058502197\n",
      "Epoch 18/100, Loss: 57.57059574127197\n",
      "Epoch 19/100, Loss: 51.83903694152832\n",
      "Epoch 20/100, Loss: 46.39360213279724\n",
      "Epoch 21/100, Loss: 42.20703911781311\n",
      "Epoch 22/100, Loss: 37.49357056617737\n",
      "Epoch 23/100, Loss: 34.36252522468567\n",
      "Epoch 24/100, Loss: 30.6521053314209\n",
      "Epoch 25/100, Loss: 26.826045036315918\n",
      "Epoch 26/100, Loss: 23.262545257806778\n",
      "Epoch 27/100, Loss: 19.950134754180908\n",
      "Epoch 28/100, Loss: 17.21653239428997\n",
      "Epoch 29/100, Loss: 14.28020441532135\n",
      "Epoch 30/100, Loss: 12.079261392354965\n",
      "Epoch 31/100, Loss: 9.421610653400421\n",
      "Epoch 32/100, Loss: 7.915734946727753\n",
      "Epoch 33/100, Loss: 6.088584721088409\n",
      "Epoch 34/100, Loss: 4.430907070636749\n",
      "Epoch 35/100, Loss: 3.236727088689804\n",
      "Epoch 36/100, Loss: 2.2545217126607895\n",
      "Epoch 37/100, Loss: 1.4855114491656423\n",
      "Epoch 38/100, Loss: 0.835590548813343\n",
      "Epoch 39/100, Loss: 0.4243693947792053\n",
      "Epoch 40/100, Loss: 0.3547794697806239\n",
      "Epoch 41/100, Loss: 0.4048354793339968\n",
      "Epoch 42/100, Loss: 0.6106269210577011\n",
      "Epoch 43/100, Loss: 1.015170082449913\n",
      "Epoch 44/100, Loss: 1.6585662066936493\n",
      "Epoch 45/100, Loss: 2.423720598220825\n",
      "Epoch 46/100, Loss: 3.4764572381973267\n",
      "Epoch 47/100, Loss: 4.696979284286499\n",
      "Epoch 48/100, Loss: 5.83808171749115\n",
      "Epoch 49/100, Loss: 7.324695587158203\n",
      "Epoch 50/100, Loss: 8.884003162384033\n",
      "Epoch 51/100, Loss: 10.683383703231812\n",
      "Epoch 52/100, Loss: 12.39276647567749\n",
      "Epoch 53/100, Loss: 14.686412811279297\n",
      "Epoch 54/100, Loss: 16.734278917312622\n",
      "Epoch 55/100, Loss: 18.76821994781494\n",
      "Epoch 56/100, Loss: 21.51349425315857\n",
      "Epoch 57/100, Loss: 24.207706928253174\n",
      "Epoch 58/100, Loss: 26.484285831451416\n",
      "Epoch 59/100, Loss: 29.388983249664307\n",
      "Epoch 60/100, Loss: 31.621117115020752\n",
      "Epoch 61/100, Loss: 34.58561420440674\n",
      "Epoch 62/100, Loss: 37.58723449707031\n",
      "Epoch 63/100, Loss: 40.455857276916504\n",
      "Epoch 64/100, Loss: 43.03780126571655\n",
      "Epoch 65/100, Loss: 45.80295753479004\n",
      "Epoch 66/100, Loss: 48.97736597061157\n",
      "Epoch 67/100, Loss: 51.50338172912598\n",
      "Epoch 68/100, Loss: 54.01296138763428\n",
      "Epoch 69/100, Loss: 57.008986473083496\n",
      "Epoch 70/100, Loss: 60.042877197265625\n",
      "Epoch 71/100, Loss: 62.53999137878418\n",
      "Epoch 72/100, Loss: 64.89526844024658\n",
      "Epoch 73/100, Loss: 67.55674648284912\n",
      "Epoch 74/100, Loss: 70.54476547241211\n",
      "Epoch 75/100, Loss: 72.93622398376465\n",
      "Epoch 76/100, Loss: 75.08102416992188\n",
      "Epoch 77/100, Loss: 77.25604152679443\n",
      "Epoch 78/100, Loss: 78.95941638946533\n",
      "Epoch 79/100, Loss: 81.04524421691895\n",
      "Epoch 80/100, Loss: 82.53250312805176\n",
      "Epoch 81/100, Loss: 83.95626068115234\n",
      "Epoch 82/100, Loss: 85.54583740234375\n",
      "Epoch 83/100, Loss: 86.81919860839844\n",
      "Epoch 84/100, Loss: 87.69373893737793\n",
      "Epoch 85/100, Loss: 88.41181755065918\n",
      "Epoch 86/100, Loss: 88.9384880065918\n",
      "Epoch 87/100, Loss: 89.30286121368408\n",
      "Epoch 88/100, Loss: 89.4188289642334\n",
      "Epoch 89/100, Loss: 89.2922887802124\n",
      "Epoch 90/100, Loss: 89.00062942504883\n",
      "Epoch 91/100, Loss: 88.36655616760254\n",
      "Epoch 92/100, Loss: 87.44208335876465\n",
      "Epoch 93/100, Loss: 86.5704288482666\n",
      "Epoch 94/100, Loss: 85.38457012176514\n",
      "Epoch 95/100, Loss: 83.61659526824951\n",
      "Epoch 96/100, Loss: 82.1865873336792\n",
      "Epoch 97/100, Loss: 80.16739654541016\n",
      "Epoch 98/100, Loss: 77.96405792236328\n",
      "Epoch 99/100, Loss: 75.8465166091919\n",
      "Epoch 100/100, Loss: 72.96469497680664\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "#data \n",
    "x = torch.tensor([[1.],[2.],[3.],[4.],[5.],[6.],[7.],[8.]])\n",
    "y = torch.tensor([[2.],[4.],[6.],[8.],[10.],[12.],[14.],[16.]])\n",
    "dataset = TensorDataset(x,y)\n",
    "dataloader = DataLoader(dataset,batch_size=2,shuffle=True)\n",
    "#model\n",
    "class simplenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(1,1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = simplenet()\n",
    "#loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.01)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        yp = model(batch_x)\n",
    "        loss = criterion(yp, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
